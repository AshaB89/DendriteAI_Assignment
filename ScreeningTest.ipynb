{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install striprtf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfTe54oKld8D",
        "outputId": "2904ec9a-7b3d-47db-f747-587839b3d95f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting striprtf\n",
            "  Downloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
            "Installing collected packages: striprtf\n",
            "Successfully installed striprtf-0.0.26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing required libraries\n",
        "from striprtf.striprtf import rtf_to_text\n",
        "import json\n",
        "import pandas as pd\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_regression, f_classif\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, GradientBoostingRegressor, GradientBoostingClassifier, ExtraTreesRegressor, ExtraTreesClassifier\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, SGDRegressor, LogisticRegression, RidgeClassifier, Lasso, SGDClassifier\n",
        "from sklearn.svm import SVR, SVC\n",
        "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit, StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "from sklearn.preprocessing import LabelBinarizer"
      ],
      "metadata": {
        "id": "i2RyZFMTGqc8"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read from RTF file and convert to plain text\n",
        "rtf_file = '/content/algoparams_from_ui.json.rtf'\n",
        "try:\n",
        "    with open(rtf_file, 'r') as file:  # Open the file in text mode\n",
        "        rtf_content = file.read()  # Read the content as a string\n",
        "        plain_text_content = rtf_to_text(rtf_content)\n",
        "except FileNotFoundError:\n",
        "    print(\"File not found.\")"
      ],
      "metadata": {
        "id": "i7fwhNQwSB4s"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the JSON data\n",
        "try:\n",
        "    json_data = json.loads(plain_text_content)\n",
        "except json.JSONDecodeError as e:\n",
        "    print(\"Error parsing JSON:\", e)"
      ],
      "metadata": {
        "id": "0HXv1byzX9EI"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the target and type of regression to be run\n",
        "target = json_data[\"design_state_data\"][\"target\"][\"target\"]\n",
        "regression_type = json_data[\"design_state_data\"][\"target\"][\"prediction_type\"]\n",
        "print(\"Target:\", target)\n",
        "print(\"Regression Type:\", regression_type)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWR8Sb0vT3Dt",
        "outputId": "3cdd20c8-9ed2-4e24-8cc8-d2384b404f84"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target: petal_width\n",
            "Regression Type: Regression\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the dataset\n",
        "file_path = 'iris.csv'\n",
        "\n",
        "# Read the CSV file into a DataFrame\n",
        "df = pd.read_csv(file_path)"
      ],
      "metadata": {
        "id": "u3etcSc5rn9J"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply feature handling\n",
        "feature_handling = json_data[\"design_state_data\"][\"feature_handling\"]\n",
        "# Iterate through the features and apply missing value imputation as specified in JSON\n",
        "for feature_name, feature_details in feature_handling.items():\n",
        "    if \"missing_values\" in feature_details[\"feature_details\"] and feature_details[\"feature_details\"][\"missing_values\"] == \"Impute\":\n",
        "        impute_with = feature_details[\"feature_details\"][\"impute_with\"]\n",
        "        impute_value = feature_details[\"feature_details\"][\"impute_value\"]\n",
        "        if impute_with == \"Average of values\":\n",
        "            df[feature_name].fillna(df[feature_name].mean(), inplace=True)\n",
        "        elif impute_with == \"custom\":\n",
        "            df[feature_name].fillna(impute_value, inplace=True)"
      ],
      "metadata": {
        "id": "WXod_Cxqqv8E"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the feature reduction method from JSON\n",
        "if \"feature_reduction\" in json_data['design_state_data']:\n",
        "    if \"No Reduction\" in json_data['design_state_data']['feature_reduction'] and json_data['design_state_data']['feature_reduction'][\"No Reduction\"].get(\"is_selected\", True):\n",
        "      feature_reduction_method = \"No Reduction\"\n",
        "      num_of_features_to_keep = int(json_data['design_state_data'][\"feature_reduction\"][\"No Reduction\"][\"num_of_features_to_keep\"])\n",
        "    elif \"Tree-based\" in json_data['design_state_data']['feature_reduction'] and json_data['design_state_data']['feature_reduction'][\"Tree-based\"].get(\"is_selected\", True):\n",
        "      feature_reduction_method = \"Tree-based\"\n",
        "      num_of_features_to_keep = int(json_data['design_state_data']['feature_reduction'][\"Tree-based\"][\"num_of_features_to_keep\"])\n",
        "      num_of_trees = int(json_data['design_state_data'][\"feature_reduction\"][\"Tree-based\"][\"num_of_trees\"])\n",
        "      depth_of_trees = int(json_data['design_state_data'][\"feature_reduction\"][\"Tree-based\"][\"depth_of_trees\"])\n",
        "    elif \"Correlation with target\" in json_data['design_state_data']['feature_reduction'] and json_data['design_state_data'][\"feature_reduction\"][\"Correlation with target\"].get(\"is_selected\", True):\n",
        "      feature_reduction_method = \"Correlation with target\"\n",
        "      num_of_features_to_keep = int(json_data['design_state_data'][\"feature_reduction\"][\"Correlation with target\"][\"num_of_features_to_keep\"])\n",
        "    elif \"Principal Component Analysis\" in json_data['design_state_data'][\"feature_reduction\"] and json_data['design_state_data'][\"feature_reduction\"][\"Principal Component Analysi\"].get(\"is_selected\", True):\n",
        "      feature_reduction_method = \"Principal Component Analysis\"\n",
        "      num_of_features_to_keep = int(json_data['design_state_data'][\"feature_reduction\"][\"Principal Component Analysis\"][\"num_of_features_to_keep\"])\n",
        "    else:\n",
        "      feature_reduction_method = json_data['design_state_data'][\"feature_reduction\"][\"feature_reduction_method\"]\n",
        "      num_of_features_to_keep = int(json_data['design_state_data'][\"feature_reduction\"][\"num_of_features_to_keep\"])\n",
        "      num_of_trees = int(json_data['design_state_data'][\"feature_reduction\"][\"num_of_trees\"])\n",
        "      depth_of_trees = int(json_data['design_state_data'][\"feature_reduction\"][\"depth_of_trees\"])\n",
        "    print(\"Feature Reduction Method:\", feature_reduction_method)\n",
        "else:\n",
        "    print(\"Feature reduction not specified\")"
      ],
      "metadata": {
        "id": "8uoFxtH1tEcF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b57b9070-bf8f-43b3-f963-f8d9b5addd6a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Reduction Method: Tree-based\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply feature reduction method\n",
        "if feature_reduction_method == \"No Reduction\":\n",
        "    # No feature reduction, use the original data\n",
        "    if regression_type == \"Classification\":\n",
        "    # Classification task\n",
        "      X = df\n",
        "      y = 'species'\n",
        "    elif regression_type == \"Regression\":\n",
        "      # Regression task\n",
        "      X = df.drop(columns=['species'])\n",
        "      y = target\n",
        "    else:\n",
        "      raise ValueError(\"Invalid regression_type. Please specify 'Regression' or 'Classification'.\")\n",
        "    X = X\n",
        "elif feature_reduction_method == \"Tree-based\":\n",
        "    # Check if it's a classification or regression task based on the target variable's data type\n",
        "    if regression_type == \"Classification\":\n",
        "    # Classification task\n",
        "      features = df.drop(columns=['species'])\n",
        "      y = 'species'\n",
        "      feature_reduction_model = RandomForestClassifier(n_estimators=num_of_trees, max_depth=depth_of_trees)\n",
        "    elif regression_type == \"Regression\":\n",
        "      # Regression task\n",
        "      features = df.drop(columns=[target,'species'])\n",
        "      y = target\n",
        "      feature_reduction_model = RandomForestRegressor(n_estimators=num_of_trees, max_depth=depth_of_trees)\n",
        "    else:\n",
        "      raise ValueError(\"Invalid regression_type. Please specify 'Regression' or 'Classification'.\")\n",
        "    # Fit the model to your data\n",
        "    feature_reduction_model.fit(features, df[y])\n",
        "    # Get feature importances\n",
        "    feature_importances = feature_reduction_model.feature_importances_\n",
        "    # Select the top 'num_of_features_to_keep' features based on importance\n",
        "    top_features_indices = feature_importances.argsort()[-num_of_features_to_keep:][::-1]\n",
        "    # Extract the top features\n",
        "    top_features = features.columns[top_features_indices]\n",
        "    # Create a new DataFrame with only the top features and the target variable\n",
        "    X = df[top_features.tolist()+[y]]\n",
        "elif feature_reduction_method == \"Correlation with target\":\n",
        "    if regression_type == \"Classification\":\n",
        "    # Classification task\n",
        "      features = df.drop(columns=['species'])\n",
        "      y = 'species'\n",
        "      feature_reduction_model = SelectKBest(score_func=f_classif, k=num_of_features_to_keep)\n",
        "    elif regression_type == \"Regression\":\n",
        "      # Regression task\n",
        "      features = df.drop(columns=[target,'species'])\n",
        "      y = target\n",
        "      feature_reduction_model = SelectKBest(score_func=f_regression, k=num_of_features_to_keep)\n",
        "    else:\n",
        "      raise ValueError(\"Invalid regression_type. Please specify 'Regression' or 'Classification'.\")\n",
        "    # Fit the selector on your data and target\n",
        "    feature_reduction_model.fit_transform(features, df[y])\n",
        "    # Get the selected feature indices\n",
        "    top_features_indices = feature_reduction_model.get_support(indices=True)\n",
        "    # Extract the top features\n",
        "    top_features = features.columns[top_features_indices]\n",
        "    # Create a new DataFrame with only the top features and the target variable\n",
        "    X = df[top_features.tolist()+[y]]\n",
        "elif feature_reduction_method == \"Principal Component Analysis\":\n",
        "    if regression_type == \"Classification\":\n",
        "    # Classification task\n",
        "      X = df.drop(columns=['species'])\n",
        "      y = 'species'\n",
        "    elif regression_type == \"Regression\":\n",
        "      # Regression task\n",
        "      X = df.drop(columns=[target,'species'])\n",
        "      y = target\n",
        "    else:\n",
        "      raise ValueError(\"Invalid regression_type. Please specify 'Regression' or 'Classification'.\")\n",
        "    # Standardize the features\n",
        "    scaler = StandardScaler()\n",
        "    scaled_features = scaler.fit_transform(features)\n",
        "    # Perform PCA for feature reduction\n",
        "    pca = PCA(n_components=num_of_features_to_keep)\n",
        "    principal_components = pca.fit_transform(scaled_features)\n",
        "    # Create a DataFrame with the top principal components as columns\n",
        "    top_features = pd.DataFrame(data=principal_components, columns=[f'PC{i}' for i in range(1, num_of_features_to_keep + 1)])\n",
        "    # Create a new DataFrame with only the top features and the target variable\n",
        "    X = df[top_features.tolist()+[y]]\n",
        "else:\n",
        "  print(\"feature_reduction method not specified\")\n"
      ],
      "metadata": {
        "id": "9HbaQvCnBfGR"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the train_ratio and random_seed based on JSON\n",
        "train_ratio = int(json_data['design_state_data'][\"train\"][\"train_ratio\"])\n",
        "if train_ratio==0:\n",
        "  train_ratio = 0.8 #default\n",
        "random_seed =json_data['design_state_data'][\"train\"][\"random_seed\"]\n",
        "\n",
        "# Split the dataset based on the configuration\n",
        "if json_data['design_state_data']['train']['k_fold']:\n",
        "    kf = KFold(n_splits=5, shuffle=True, random_state=random_seed)\n",
        "    for train_index, test_index in kf.split(X):\n",
        "        train_data, test_data = X.iloc[train_index], X.iloc[test_index]\n",
        "else:\n",
        "    train_data, test_data = train_test_split(X, test_size=1 - train_ratio, random_state=random_seed)\n"
      ],
      "metadata": {
        "id": "vlr5c2QEw49C"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create custom lists of model names for regression and classification\n",
        "regression_models = [\"RandomForestRegressor\",\"GBTRegressor\",\"LinearRegression\", \"RidgeRegression\", \"LassoRegression\", \"ElasticNetRegression\",\"SVM\",\"SGD\",\"KNN\",\"extra_random_trees\",\"neural_network\"]\n",
        "classification_models = [\"RandomForestClassifier\", \"GBTClassifier\", \"LogisticRegression\",\"DecisionTreeClassifier\", \"SVM\", \"SGD\",\"KNN\",\"extra_random_trees\",\"neural_network\"]"
      ],
      "metadata": {
        "id": "SJ9yYdaymKgp"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Regression Models\n",
        "regression_model_map = {\n",
        "    \"RandomForestRegressor\": RandomForestRegressor,\n",
        "    \"GBTRegressor\": GradientBoostingRegressor,\n",
        "    \"LinearRegression\": LinearRegression,\n",
        "    \"RidgeRegression\": Ridge,\n",
        "    \"LassoRegression\": Lasso,\n",
        "    \"ElasticNetRegression\": ElasticNet,\n",
        "    \"KNN\": KNeighborsRegressor,\n",
        "    \"SVM\": SVR,\n",
        "    \"SGD\": SGDRegressor,\n",
        "    \"extra_random_trees\": ExtraTreesRegressor,\n",
        "    \"neural_network\": MLPRegressor,\n",
        "}\n",
        "\n",
        "# Classification Models\n",
        "classification_model_map = {\n",
        "    \"RandomForestClassifier\": RandomForestClassifier,\n",
        "    \"GBTClassifier\": GradientBoostingClassifier,\n",
        "    \"LogisticRegression\": LogisticRegression,\n",
        "    \"DecisionTreeClassifier\": DecisionTreeClassifier,\n",
        "    \"SVM\": SVC,\n",
        "    \"SGD\": SGDClassifier,\n",
        "    \"KNN\": KNeighborsClassifier,\n",
        "    \"extra_random_trees\": ExtraTreesClassifier,\n",
        "    \"neural_network\": MLPClassifier,\n",
        "}\n",
        "\n",
        "# Store the respective hyperparameters of each model from JSON\n",
        "algorithm_data = json_data['design_state_data']['algorithms']\n",
        "\n",
        "def generate_hyperparameters(model_name):\n",
        "    model_config = algorithm_data[model_name]\n",
        "    if model_name == 'RandomForestClassifier' or model_name =='RandomForestRegressor':\n",
        "      min_trees = int(model_config[\"min_trees\"])\n",
        "      max_trees = int(model_config[\"max_trees\"])\n",
        "      min_depth = int(model_config[\"min_depth\"])\n",
        "      max_depth = int(model_config[\"max_depth\"])\n",
        "      min_samples_per_leaf_min_value = int(model_config[\"min_samples_per_leaf_min_value\"])\n",
        "      min_samples_per_leaf_max_value = int(model_config[\"min_samples_per_leaf_max_value\"])\n",
        "      parallelism = int(model_config[\"parallelism\"])\n",
        "\n",
        "      hyperparameters = {\n",
        "        \"n_estimators\": [min_trees, max_trees],\n",
        "        \"max_depth\": [min_depth, max_depth],\n",
        "        \"min_samples_leaf\": [min_samples_per_leaf_min_value, min_samples_per_leaf_max_value],\n",
        "        \"max_features\": [1.0],\n",
        "        \"n_jobs\": [1] if parallelism == 0 else [parallelism]\n",
        "      }\n",
        "    if model_name == 'GBTClassifier' or model_name =='GBTRegressor':\n",
        "      fixed_number = model_config[\"fixed_number\"]\n",
        "      min_stepsize = model_config[\"min_stepsize\"]\n",
        "      max_stepsize = model_config[\"max_stepsize\"]\n",
        "      min_iter = model_config[\"min_iter\"]\n",
        "      max_iter = model_config[\"max_iter\"]\n",
        "      min_depth = model_config[\"min_depth\"]\n",
        "      max_depth = model_config[\"max_depth\"]\n",
        "      num_of_BoostingStages=model_config['num_of_BoostingStages']\n",
        "\n",
        "      hyperparameters = {\n",
        "        \"n_estimators\": num_of_BoostingStages,\n",
        "        \"max_depth\": [min_depth, max_depth],\n",
        "        \"subsample\": [0.1,1.0],\n",
        "        \"max_features\": [1.0],\n",
        "      }\n",
        "    if model_name == 'LinearRegression' or model_name =='LogisticRegression':\n",
        "      parallelism = int(model_config[\"parallelism\"])\n",
        "      min_iter = int(model_config[\"min_iter\"])\n",
        "      max_iter = int(model_config[\"max_iter\"])\n",
        "      min_regparam = float(model_config[\"min_regparam\"])\n",
        "      max_regparam = float(model_config[\"max_regparam\"])\n",
        "      min_elasticnet = float(model_config[\"min_elasticnet\"])\n",
        "      max_elasticnet = float(model_config[\"max_elasticnet\"])\n",
        "      if model_name == 'LinearRegression':\n",
        "        hyperparameters = {\n",
        "        \"n_jobs\":[1] if parallelism == 0 else [parallelism],\n",
        "        }\n",
        "      if model_name == 'LogisticRegression':\n",
        "        hyperparameters = {\n",
        "        \"C\": [min_regparam, max_regparam],\n",
        "        \"max_iter\": [min_iter, max_iter],\n",
        "        \"n_jobs\": [1] if parallelism == 0 else [parallelism],\n",
        "        \"l1_ratio\": [min_elasticnet, max_elasticnet],\n",
        "      }\n",
        "    if model_name == 'RidgeRegression' or model_name =='LassoRegression':\n",
        "      min_iter = int(model_config[\"min_iter\"])\n",
        "      max_iter = int(model_config[\"max_iter\"])\n",
        "      min_regparam = float(model_config[\"min_regparam\"])\n",
        "      max_regparam = float(model_config[\"max_regparam\"])\n",
        "      hyperparameters = {\n",
        "        \"alpha\": [min_regparam, max_regparam],\n",
        "        \"max_iter\": [min_iter, max_iter],\n",
        "      }\n",
        "    if model_name == 'ElasticNetRegression':\n",
        "      min_iter = int(model_config[\"min_iter\"])\n",
        "      max_iter = int(model_config[\"max_iter\"])\n",
        "      min_regparam = float(model_config[\"min_regparam\"])\n",
        "      max_regparam = float(model_config[\"max_regparam\"])\n",
        "      min_elasticnet = float(model_config[\"min_elasticnet\"])\n",
        "      max_elasticnet = float(model_config[\"max_elasticnet\"])\n",
        "      hyperparameters = {\n",
        "        \"alpha\": [min_regparam, max_regparam],\n",
        "        \"l1_ratio\": [min_elasticnet, max_elasticnet],\n",
        "        \"max_iter\": [min_iter, max_iter],\n",
        "      }\n",
        "    if model_name =='DecisionTreeClassifier':\n",
        "      min_depth = model_config[\"min_depth\"]\n",
        "      max_depth = model_config[\"max_depth\"]\n",
        "      use_gini = model_config[\"use_gini\"]\n",
        "      use_entropy = model_config[\"use_entropy\"]\n",
        "      min_samples_per_leaf = model_config.get(\"min_samples_per_leaf\", [])\n",
        "      use_best = model_config[\"use_best\"]\n",
        "      use_random = model_config[\"use_random\"]\n",
        "      hyperparameters = {\n",
        "        \"max_depth\": [min_depth, max_depth],\n",
        "        \"criterion\": [\"gini\" if use_gini else \"entropy\"],\n",
        "        \"min_samples_leaf\": min_samples_per_leaf,\n",
        "        \"splitter\": [\"best\" if use_best else \"random\"],\n",
        "      }\n",
        "    if model_name=='SVM':\n",
        "      c_value = model_config[\"c_value\"]\n",
        "      kernel = [\"linear\", \"rbf\", \"poly\", \"sigmoid\"] if model_config[\"linear_kernel\"] else []\n",
        "      tol = model_config[\"tolerance\"]\n",
        "      max_iter = model_config[\"max_iterations\"]\n",
        "      auto = model_config[\"auto\"]\n",
        "      scale = model_config[\"scale\"]\n",
        "      hyperparameters = {\n",
        "        \"C\": c_value,\n",
        "        \"kernel\": kernel,\n",
        "        \"gamma\": [0.001, 1.0],\n",
        "        \"tol\": [tol],\n",
        "        \"max_iter\": [max_iter],\n",
        "        \"shrinking\": [auto],\n",
        "      }\n",
        "    if model_name=='SGD':\n",
        "      loss = ['huber']\n",
        "      tol = model_config[\"tolerance\"]\n",
        "      alpha = model_config[\"alpha_value\"]\n",
        "      l1_ratio = 0.5 if model_config[\"use_l1_regularization\"] == \"on\" else 0.0\n",
        "      l2_ratio = 0.5 if model_config[\"use_l2_regularization\"] == \"on\" else 0.0\n",
        "      elastic_net = True if model_config[\"use_elastic_net_regularization\"] else False\n",
        "      hyperparameters = {\n",
        "        \"loss\": loss,\n",
        "        \"penalty\": [\"elasticnet\" if elastic_net else \"l1\" if l1_ratio > 0.0 else \"l2\"],\n",
        "        \"alpha\": alpha,\n",
        "        \"l1_ratio\": [l1_ratio],\n",
        "        \"tol\": [tol],\n",
        "        \"max_iter\": [1,50],\n",
        "      }\n",
        "    if model_name=='KNN':\n",
        "      k_value = model_config[\"k_value\"]\n",
        "      weights = [\"uniform\", \"distance\"] if model_config[\"distance_weighting\"] else []\n",
        "      p_value = [1.0,2.0] if model_config[\"p_value\"] == 0 else model_config[\"p_value\"]\n",
        "      hyperparameters = {\n",
        "        \"n_neighbors\": k_value,\n",
        "        \"weights\": weights,\n",
        "        \"algorithm\": [\"auto\"],\n",
        "        \"p\": p_value,\n",
        "      }\n",
        "    if model_name=='extra_random_trees':\n",
        "      num_of_trees = model_config[\"num_of_trees\"]\n",
        "      feature_sampling_statergy = model_config[\"feature_sampling_statergy\"]\n",
        "      max_depth = model_config[\"max_depth\"]\n",
        "      min_samples_per_leaf = model_config[\"min_samples_per_leaf\"]\n",
        "      parallelism = model_config[\"parallelism\"]\n",
        "      hyperparameters = {\n",
        "        \"n_estimators\": num_of_trees,\n",
        "        \"max_features\": [\"sqrt\", \"log2\"] if feature_sampling_statergy == \"Square root and Logarithm\" else [\"auto\"],\n",
        "        \"max_depth\": max_depth,\n",
        "        \"min_samples_leaf\": min_samples_per_leaf,\n",
        "        \"n_jobs\": [1] if parallelism == 0 else [parallelism],\n",
        "      }\n",
        "    if model_name=='neural_network':\n",
        "      hidden_layer_sizes = model_config[\"hidden_layer_sizes\"]\n",
        "      solver = model_config[\"solver\"]\n",
        "      early_stopping = model_config[\"early_stopping\"]\n",
        "      initial_learning_rate = model_config[\"initial_learning_rate\"]\n",
        "      hyperparameters = {\n",
        "        \"hidden_layer_sizes\": hidden_layer_sizes,\n",
        "        \"activation\": [\"relu\", \"tanh\", \"logistic\"],\n",
        "        \"solver\": ['adam'],\n",
        "        \"max_iter\": [1,50],\n",
        "        \"tol\": [model_config[\"convergence_tolerance\"]],\n",
        "        \"early_stopping\": [early_stopping],\n",
        "        \"learning_rate_init\": [0.1, 2.0],\n",
        "        \"batch_size\": [\"auto\" if model_config[\"automatic_batching\"] else \"none\"],\n",
        "      }\n",
        "    return hyperparameters"
      ],
      "metadata": {
        "id": "mVf5A2vWgOPg"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = {}\n",
        "# Create models based on the selected regression_type\n",
        "if regression_type == \"Regression\":\n",
        "    for model_name, model_class in regression_model_map.items():\n",
        "        models[model_name] = model_class()\n",
        "elif regression_type == \"Classification\":\n",
        "    for model_name, model_class in classification_model_map.items():\n",
        "        models[model_name] = model_class()\n",
        "else:\n",
        "    raise ValueError(\"Invalid regression_type. Please specify 'Regression' or 'Classification'.\")\n",
        "# Define hyperparameter tuning strategy based on JSON\n",
        "hyperparameter_strategy = json_data['design_state_data']['hyperparameters']['stratergy']\n",
        "# Perform hyperparameter tuning and fit/predict on each model\n",
        "for model_name, model in models.items():\n",
        "  #Comment below 'if condition' to check all models regardless of is_selected parameter\n",
        "  if json_data['design_state_data'][\"algorithms\"][model_name][\"is_selected\"]:\n",
        "    if hyperparameter_strategy == \"Grid Search\":\n",
        "        # Define the hyperparameters to search for this model\n",
        "        param_grid = generate_hyperparameters(model_name)\n",
        "        jobs = int(json_data['design_state_data']['hyperparameters']['parallelism'])\n",
        "        grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=KFold(n_splits=6), n_jobs=jobs)\n",
        "        # Fit the grid search to your data\n",
        "        if regression_type == \"Regression\":\n",
        "          grid_search.fit(train_data.drop(columns=[y]), train_data[y])\n",
        "          best_model = grid_search.best_estimator_\n",
        "          # Print the best hyperparameters and the corresponding score\n",
        "          #print(\"Best Hyperparameters: \", grid_search.best_params_)\n",
        "          #print(\"Best Score: \", grid_search.best_score_)\n",
        "          # Fit the best model to the training data\n",
        "          best_model.fit(train_data.drop(columns=[y]), train_data[y])\n",
        "          # Make predictions on the test set\n",
        "          predictions = best_model.predict(test_data.drop(columns=[y]))\n",
        "          actual_values = test_data[y]\n",
        "          # Calculate Mean Squared Error\n",
        "          mse = mean_squared_error(actual_values, predictions)\n",
        "          print(f\"Model: {model_name}, Mean Squared Error: {mse}\")\n",
        "          # Calculate R-squared (Coefficient of determination)\n",
        "          r2 = r2_score(actual_values, predictions)\n",
        "          print(f\"Model: {model_name}, R-squared: {r2}\")\n",
        "          # Calculate Mean Absolute Error\n",
        "          mae = mean_absolute_error(actual_values, predictions)\n",
        "          print(f\"Model: {model_name}, Mean Absolute Error: {mae}\")\n",
        "        if regression_type == \"Classification\":\n",
        "          grid_search.fit(train_data.drop(columns=[y]), train_data[y])\n",
        "          best_model = grid_search.best_estimator_\n",
        "          # Print the best hyperparameters and the corresponding score\n",
        "          #print(\"Best Hyperparameters: \", grid_search.best_params_)\n",
        "          #print(\"Best Score: \", grid_search.best_score_)\n",
        "          # Fit the best model to the training data\n",
        "          best_model.fit(train_data.drop(columns=[y]), train_data[y])\n",
        "          # Make predictions on the test set\n",
        "          predictions = best_model.predict(test_data.drop(columns=[y]))\n",
        "          actual_labels = test_data[y]\n",
        "          # Calculate Accuracy\n",
        "          accuracy = accuracy_score(actual_labels, predictions)\n",
        "          print(f\"Model: {model_name}, Accuracy: {accuracy}\")\n",
        "          # Calculate Precision\n",
        "          precision = precision_score(actual_labels, predictions,average=None)\n",
        "          print(f\"Model: {model_name}, Precision: {precision}\")\n",
        "          # Calculate Recall\n",
        "          recall = recall_score(actual_labels, predictions,average=None)\n",
        "          print(f\"Model: {model_name}, Recall: {recall}\")\n",
        "          # Calculate F1 Score\n",
        "          f1 = f1_score(actual_labels, predictions,average=None)\n",
        "          print(f\"Model: {model_name}, F1 Score: {f1}\")\n",
        "          # Calculate ROC AUC Score\n",
        "          # Use LabelBinarizer to convert string labels to binary format\n",
        "          label_binarizer = LabelBinarizer()\n",
        "          actual_binary = label_binarizer.fit_transform(actual_labels)\n",
        "          predicted_binary = label_binarizer.transform(predictions)\n",
        "          roc_auc = roc_auc_score(actual_binary, predicted_binary, average=None)\n",
        "          print(f\"Model: {model_name}, ROC AUC: {roc_auc}\")\n",
        "    else:\n",
        "        raise ValueError(\"Invalid hyperparameter tuning strategy.\")"
      ],
      "metadata": {
        "id": "uHB4RuPa9cI6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cb99cca-5327-4867-917a-8e7e3ab57403"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: RandomForestRegressor, Mean Squared Error: 0.049255435240653504\n",
            "Model: RandomForestRegressor, R-squared: 0.8974058836895366\n",
            "Model: RandomForestRegressor, Mean Absolute Error: 0.15047679850106324\n"
          ]
        }
      ]
    }
  ]
}